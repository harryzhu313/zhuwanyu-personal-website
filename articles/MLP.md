---
title: 从注意力到记忆：理解 Transformer 中的 MLP
date: 2025-08-22
categories: [深度学习]
cover: https://image.harryrou.wiki/2025-08-22-mlp.png
description: " "
---


## 一句话版

Attention注意力头类似于我们的工作记忆，在**上下文**中“看谁和谁有关”。

MLP 类似于我们的长期记忆，可以存储事实性知识。

## MLP 是什么

在 Transformer 中，MLP 就是一段对每个 token 单独运算的小型神经网络，通常只有两层线性变换（Linear），中间有一个“弯”的激活函数（如 GELU / SwiGLU / ReLU）：

- 首先扩展维度（把信息摊开）
- 然后通过激活函数（产生非线性，实现“如果…则…”的决策）
- 最后再收回到原维度
    
![](https://image.harryrou.wiki/2025-08-09-N2037cvU.jpg)

## 举例说明

  * 例如在句子“Michael Jordan plays \_\_\_”中，
  * 注意力机制通过“Michael”和“Jordan”的组合，将预测引导至“basketball”。
  * 同时，模型还可能关联其他和 Michael Jordan 相关的特征，例如“Chicago Bulls”、“number23”、“born 1963”等。

## MLP在Transformer中的作用

### 非线性决策

只有 MLP 中的激活函数能实现非线性变换。这使得模型不只局限于简单的线性加权组合，而能够掌握和表达更复杂的组合逻辑和交叉条件，比如当同时满足多个条件时更倾向于某种特定输出。

它能表达“若 A 且 B → C”之类的组合条件；这正是单层感知器无法处理 XOR 等非线性可分问题的根本原因。

### 特征提取

MLP 会在每个 token 的向量里生成抽象特征，例如判断一个 token 是不是人名、是不是城市、是否在引号内、是否复数等等。

虽然在 MLP 中，每个 token 都是独立运算的，但输入的向量已经由注意力头注入了丰富的上下文信息。

## 为什么说 MLP 存储事实？

从 Transformer 的参数分布来看，MLP 存储了大约 2/3 的参数。例如，在 GPT-3 中，MLP 部分参数占比达到总量的 115,964,116,992/1750 亿。

这些参数最初是随机初始化的，通过海量互联网数据训练后（LLM 预训练），便“学会”了人类的知识。这与人类通过阅读和记忆知识的过程相似，只不过人类记忆知识的物理介质是大脑神经元与突触之间的联结，而 Transformer 模型则是参数权重。这些参数最终决定了模型的行为模式。

### 预测即压缩，压缩即智能，智能即具备理解力

但需要强调，这种“学习”并非将知识以硬编码的形式存入模型，而是通过“高度压缩”的形式存储特征和模式。当模型进行下一个词的预测时，它便能基于上下文语义（attention）、MLP 的非线性决策以及特征提取，综合确定下一个 token 的输出方向。

Ilya 在多个场合指出，“预测下一个 token”的过程就是“压缩”，他认为预测即压缩，压缩则是智能的来源。

这种压缩方式可类比为一种“有损”压缩的解压过程：源文件 → 压缩 → 解压缩。

## 为什么 Transformer 的泛化能力很好？

研究证据表明，单一神经元很少单独存储如“Michael”这样明确的概念。与人类神经元类似，一个概念通常是由多个神经元同时激活表示的。

**superposition 超叠加**：同一个神经元在不同上下文可能表示不同的特征（比如在今天检测“引号内”，明天检测“URL 模式”），而不是给每个神经元固定单一的特征。

这种特性提高了神经元对不同任务的泛化能力，随着模型变大（维度更多），这种特征的扩展性和表达能力会进一步增强。

但也正因为一个神经元表示多个特征，在陌生或模糊的语境下，可能会出现我们常说的“幻觉 Hallucinations”问题。
