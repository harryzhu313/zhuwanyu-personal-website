---
title: 神经网络是如何学习的？
date: 2025-05-23
categories: [深度学习]
cover: https://image.harryrou.wiki/2025-11-05-061006.jpg
description: ""
---



大语言模型（LLM）的核心技术是**预训练**。无论从时间、成本还是数据量来看，这一过程几乎占据了模型训练99% 的资源。模型的学习过程类似于人类的自主学习过程。那么模型到底是怎样进行学习的呢？



一句话概括：模型通过计算预测结果与真实值之间的误差（成本函数），再利用反向传播算法计算梯度，接着使用**梯度下降（gradient descent）** 等优化算法逐步调整模型参数（权重和偏置），最终使误差最小，从而获得精准的预测能力。



听起来复杂，但逐步拆解更容易理解。本文重点解释成本函数和梯度下降两个关键概念，反向传播算法作为下一期内容单独解释。

## 成本函数 cost function

首先我们要知道模型在学习过程中做什么？以及模型在完成学习后，我们将会得到什么？

本质上，大语言模型只做一件事：预测下一个 token（词元）。无论训练还是应用阶段，核心都是预测下一个词元的能力。而**成本函数 cost function**就是用来衡量模型预测结果与真实数据之间差距的数学方法。

$$\hat{y} - y$$
简单理解：

- 预测值$(\hat{y})$与真实值$(y)$的差距越小，模型越准确。
- 常用的一种成本函数是均方误差（MSE），计算方法为：

$$\text{MSE} = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2$$
 - 预测值与实际值的差距之所以被平方，是因为大的误差对整体损失的影响更大。

 预测值$(\hat{y})$的计算通常形式为：
$$\hat{y} = wx + b$$

模型初始时，权重（w）和偏置（b）都是随机生成的，训练过程就是不断更新这些参数，直到误差达到最小为止。当参数稳定且误差最小时，就可以将模型部署使用。这就是我们经常听说的 GPT-4 有 1.8 万亿参数，GPT-4.5 可能有 18 万亿参数的含义


模型学习的本质，类似于人类的学习过程。人类并非通过直接记住答案来学习，而是通过不断尝试、不断犯错并改正来找到解决问题的方法。大语言模型也是如此，不断地通过寻找误差的最小值来提升预测能力。

![](https://image.harryrou.wiki/2025-05-23-083007.png)
## 梯度下降 gradient descent

梯度下降的概念可以用一个简单比喻理解：模型寻找最小误差的过程，就像一群人在山顶上寻找最低山谷的位置。刚开始，大家的位置随机分布，然后逐步朝着下降的方向移动，最终都能抵达最低点。

![](https://image.harryrou.wiki/2025-05-23-082854.png)

**梯度**指的是成本函数在当前参数处的变化方向。简单来说，就是在当前位置判断哪个方向下降最快，模型就向那个方向调整参数。

如果观察一个训练过程的终端日志，我们主要关注的就是成本函数的下降趋势：

![](https://image.harryrou.wiki/2025-11-05-060714.png)

在大量迭代后，模型的输出会逐渐从随机变为准确。如下图所示，是 Andrey Karpathy 在一次演讲中展示的示例：用莎士比亚作品训练的一个小模型，最初生成完全随机的字符，经过 30000 次迭代后逐渐形成了莎士比亚风格的文本。

![](https://image.harryrou.wiki/2025-11-05-060654.png)


# 启发

对比大语言模型的学习与人类的学习，能发现一些共通之处：**实际值**就像我们想达成的目标（比如一道题的正确答案）；**预测值**则是我们实际的行动结果。通过持续试错（梯度下降），我们不断改进自己的行为，逐渐接近目标。因此，犯错并非坏事，反而极有价值。我们不应害怕错误，而应欢迎错误，因为每次发现错误，就意味着离成功更近了一步。另外，大语言模型这类自主学习的 AI 与传统编程（专家系统）AI 的根本区别是，机器学习让计算机具备了类似人类“举一反三”的泛化能力。这与我们通过自学真正理解的知识，能够自由迁移运用到新情境的能力极为相似，而死记硬背的知识则无法做到这一点。

![](https://image.harryrou.wiki/2025-05-23-082717.png)

通过这样的对比，我们不仅更深入地理解了模型学习的原理，也对人类自身的学习过程有了更清晰的认识。对通过自学真正理解的知识能够自由迁移，举一反三，而死记硬背的知识不能做到这一点。